# Preferred Networks Reinforcement Learning Task (Solutions)

This repository contains my solutions in the Preferred Networks Reinforcement
Learning problem set. The list of tasks can be found [here](https://github.com/pfnet/intern-coding-tasks/tree/master/2017/ml).
This year, the problem requires the development of a reinforcement learning
model to balance a cartpole using the cross-entropy method (linear policy).
There's an added challenge of using only the *Python standard library* in
performing the task, that's why you'll notice some code golfing in my work.

**Disclaimer:** I am **not** connected in any way with Preferred Networks
nor an intern in their company. So please don't take my *unchecked*
solutions as the official answer in their problem set.

## Dependencies

This repository was tested on both Linux Ubuntu 14.04.5 and Windows 10 (`cygwin`).
For the basic cartpole, only the Python 3.6.X standard library was implemented.

## Compiling the host program

The host program contains the cartpole environment and was written in C++.
To compile the program, simply write the following:

```bash
g++ -std=c++11 cartpole.cc -o cartpole.out
```

This creates the host program `cartpole.out` that can be interacted by
flushing strings into the standard output.

## Running the agent

The agent can be found in `agent.py` and interacts with the host program.
This interaction is managed by a wrapper class `CartPoleEnv`. To run the
agent, simply type the following:

```bash
./cartpole.out "python3 agent.py"
```

This runs the agent for `100` episodes with a sampling size of `100` and
elite selection of `0.1`. Various arguments can be supplied to `agent.py`
to control these hyperparameters:

| Arg | Name          | Description                                                              |
|-----|---------------|--------------------------------------------------------------------------|
| -e  | episodes      | the number of episodes to run the agent (each episode is 500 steps long) |
| -n  | sampling size | the size of the sample generated by the cross-entropy error              |
| -p  | top samples   | the number of top samples chosen for parameter update                    |
| -s  | print step    | the number of steps before printing the output observation               |

To see the list of all arguments, simpy enter the following command:

```bash
python3 agent.py -h
```

## Command-line demo

When the agent is ran, it will print the observations for every step, and the
total reward obtained for each episode. In the end, it will show the percentage
of episodes that reached a reward of 500.

```bash
./cartpole.out "python3 agent.py -e 5 -s 100"
```

Sample output:

![Sample output](./docs/pfn-demo.gif "Cartpole demo")

## Todo

- [] Add a command-line parameter to set a random seed
- [] Try a neural network model
- [] Investigate various hyperparameter effects
- [] Add API Documentation